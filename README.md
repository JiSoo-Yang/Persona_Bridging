# Persona Interview System with Bridging Inference

A multi-agent system for persona inference using **bridging discourse analysis** and **embedding-based evaluation**. The system employs a GPT-4 Tool Agent to interview Hugging Face language models, extracting implicit persona attributes through linguistic bridging relations.

## ðŸŽ¯ Overview

This system demonstrates a novel approach to persona inference by:
1. **Conducting strategic interviews** with target LLMs to elicit persona-revealing responses
2. **Extracting bridging inference relations** from conversation patterns (linguistic analysis)
3. **Constructing discourse graphs** to map implicit connections between concepts
4. **Predicting persona attributes** across four dimensions: Social Role, Personality, Background, and Interests
5. **Evaluating predictions** using embedding-based semantic similarity

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Tool Agent    â”‚  GPT-4 conducts interview & analyzes responses
â”‚     (GPT-4)     â”‚  - Generates strategic questions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Extracts bridging relations
         â”‚           - Constructs persona graph
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Target LLM    â”‚  Hugging Face model (Qwen, Llama, etc.)
â”‚  (Qwen/Llama)   â”‚  - Responds as persona
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Answers filtered to prevent leakage
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bridging Graph  â”‚  Linguistic discourse structure
â”‚   & Analysis    â”‚  - Part-of, Instrument, Theme relations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Importance scoring via centrality
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Persona Predict â”‚  Final inference with similarity eval
â”‚  + Evaluation   â”‚  - Qwen embedding-based comparison
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“ File Structure

### Core Scripts

- **`test_qwen.py`** â­ **Recommended**
  - Complete pipeline with embedding-based evaluation
  - Automatic persona extraction from agent's output
  - Qwen embedding similarity scoring (cosine similarity)
  - Comprehensive evaluation reports

### Configuration Files

- **`persona_schema.json`** - Defines persona attribute structure
  - Social roles, personality traits, backgrounds, interests
  
- **`bridging_relationships.json`** - Linguistic bridging relation definitions
  - Relation types: part-of, member-of, instrument, theme, cause-of, temporal, in

## ðŸš€ Quick Start

### Prerequisites

```bash
pip install torch transformers langchain langchain-openai langgraph
pip install matplotlib networkx numpy
```

### Setup

1. Create a `.env` file in the project root:

```bash
OPENAI_API_KEY=your-openai-api-key-here
HF_TOKEN=your-huggingface-token-here  # Optional, for gated models
```

2. Prepare configuration files:
   - `persona_schema.json` - Define your persona structure
   - `bridging_relationships.json` - Define bridging relation types

### Run the System

```bash
python test_qwen3.py
```

The system will:
1. Generate a random target persona (ground truth)
2. Conduct an interview with the target LLM
3. Extract bridging relations from conversation
4. Build and visualize discourse graph
5. Predict persona attributes
6. Evaluate predictions with embedding similarity

## ðŸ“Š Output Files

After execution, find results in the `outputs/` directory:

```
outputs/
â”œâ”€â”€ interview_results_Qwen_Qwen3-1.7B.json  # Complete interview log
â”œâ”€â”€ bridging_results.json                    # Extracted bridging relations
â”œâ”€â”€ graph_structure.json                     # Discourse graph data
â”œâ”€â”€ graph_visualization.png                  # Graph visualization
â””â”€â”€ persona_similarity.json                  # Evaluation scores
```

## ðŸ”¬ Evaluation Metrics

The system evaluates persona predictions using **cosine similarity** of Qwen embeddings:

```
ðŸ“Š GT vs Predicted - Qwen Embedding Similarity (Cosine)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1ï¸âƒ£  Social Role:     0.8523
2ï¸âƒ£  Personality:     0.7891
3ï¸âƒ£  Background:      0.8234
4ï¸âƒ£  Interests:       0.7645
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ“ˆ OVERALL AVERAGE:  0.8073
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## ðŸ§  Key Concepts

### Bridging Inference
Bridging inference captures **implicit connections** between discourse elements that require world knowledge or semantic understanding. Unlike surface-level coreference, bridging relations reveal deeper cognitive reasoning patterns.

**Example:**
```
Q: What do you do for work?
A: I spend most of my time optimizing pipelines and ensuring data quality.

Bridging Relation:
- Anchor: "work"
- Anaphor: "pipelines"
- Relation: instrument (pipelines are instruments for work)
- Inference: Reveals data engineering role without explicit statement
```

### Persona Leakage Prevention (test_qwen2.py, test_qwen3.py)

To ensure fair evaluation, target LLM responses are **redacted** to remove ground truth persona keywords:

```python
# Original response
"As a data engineer, I work with ML pipelines..."

# Redacted response (sent to Tool Agent)
"As a [REDACTED], I work with ML pipelines..."
```

This prevents the Tool Agent from trivially extracting persona attributes through keyword matching.

## âš™ï¸ Configuration

### Persona Schema Example

```json
{
  "structure": {
    "social_role": {
      "categories": {
        "professional": {
          "examples": ["data engineer", "teacher", "nurse"]
        }
      }
    },
    "personality": {
      "categories": [
        {
          "openness": {
            "description": "Creative, curious, open to new experiences"
          }
        }
      ]
    }
  }
}
```

### Bridging Relations Example

```json
{
  "relations": {
    "part-of": {
      "description": "Anaphor is a component of anchor",
      "example": "room â†’ ceiling"
    },
    "instrument": {
      "description": "Anaphor is a tool/method for anchor",
      "example": "murder â†’ knife"
    }
  }
}
```

## ðŸŽ›ï¸ Customization

### Change Target Model

```python
# In test_qwen3.py
TARGET_MODEL = "Qwen/Qwen3-1.7B"  # Change to any HF model
# Examples: "meta-llama/Llama-2-7b-chat-hf", "mistralai/Mistral-7B-v0.1"
```

### Adjust Interview Length

```python
run_interview_system(
    openai_api_key=OPENAI_API_KEY,
    target_model_name=TARGET_MODEL,
    num_questions=5,  # Change number of questions
    device="cpu"
)
```

### Modify Tool Agent Model

```python
# In test_qwen3.py
TOOL_MODEL = 'gpt-4'  # Change to 'gpt-4-turbo', 'gpt-3.5-turbo', etc.
```

## ðŸ“ˆ Research Applications

This system is designed for research in:
- **Persona inference** from conversational data
- **Bridging discourse analysis** in dialogue systems
- **Multi-agent LLM interaction** patterns
- **Implicit reasoning** in language models
- **Persona consistency** evaluation

## ðŸ› ï¸ Technical Details

### Bridging Extraction Pipeline

1. **Conversation Collection**: Agent asks strategic questions
2. **Utterance Analysis**: Parse Q&A pairs into discourse units
3. **Relation Identification**: Detect implicit connections requiring inference
4. **Graph Construction**: Build directed graph with weighted edges
5. **Centrality Scoring**: Compute PageRank/betweenness for importance ranking

### Embedding Similarity Computation

```python
# For each persona attribute
embedding_gt = encode_with_qwen(ground_truth_value)
embedding_pred = encode_with_qwen(predicted_value)
similarity = cosine_similarity(embedding_gt, embedding_pred)
```

## ðŸ“ Citation

If you use this system in your research, please cite:

```bibtex
@software{persona_interview_system,
  title={Persona Interview System with Bridging Inference},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/persona-interview-system}
}
```

## ðŸ¤ Contributing

Contributions are welcome! Areas for improvement:
- Additional bridging relation types
- Multi-turn dialogue strategies
- Alternative evaluation metrics
- Support for multilingual personas

## ðŸ“„ License

[MIT License](LICENSE)

## ðŸ” Troubleshooting

### Common Issues

**Issue**: `OPENAI_API_KEY not found`
```bash
# Solution: Create .env file with your API key
echo "OPENAI_API_KEY=sk-..." > .env
```

**Issue**: Model download fails
```bash
# Solution: Set HF_TOKEN for gated models
export HF_TOKEN=hf_...
```

**Issue**: Out of memory on GPU
```bash
# Solution: Force CPU execution
device="cpu"  # In run_interview_system()
```

**Issue**: Thread warnings on macOS
```bash
# Already handled in code via:
os.environ["TOKENIZERS_PARALLELISM"] = "false"
matplotlib.use('Agg')
```

## ðŸ“§ Contact

For questions or collaboration: [your.email@example.com]

---

**Note**: This system requires OpenAI API access for the Tool Agent (GPT-4). The target LLM runs locally via Hugging Face Transformers.